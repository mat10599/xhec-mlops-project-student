{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7019c9eb42385dabf10c857f610e93d5916e7b88"
   },
   "source": [
    "##  Abalone Age Prediction\n",
    "Description- Predicting the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c541635be5add63a3737cb7cc4f251a442b6f584"
   },
   "source": [
    "In this article I have focussed on exploratory data analysis on Abalone Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.linear_model import  Ridge\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the dataset \n",
    "data = pd.read_csv('abalone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7b6e89c41a7647df93b25706d0baabc31143fb9"
   },
   "source": [
    "From problem statement and feature discription, let's first compute the target varible of the problem ' Age' and assign it to the dataset. \n",
    "Age = 1.5+Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aae219dda94383aa845d7a6e9d80c35b9d94a74f",
    "tags": []
   },
   "outputs": [],
   "source": [
    " data['age'] = data['Rings']+1.5\n",
    " data.drop('Rings', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fd54e6744951848fbe64fe63dbc79b2856fdd97"
   },
   "source": [
    "## Univariate analysis\n",
    "Understanding feature wise statistics using various inbuilt tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2673188ba421c44e2209d6e3769d3750255eed82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7abee39862538dbf9d20b0ee5d331a3fc9a7c3ac"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3af7c59489d337f024a2b5c065e71181b62548e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93d42e2c87393a6db6b8fa18b1fc2f3b0967957a"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68e3999cb400e4f12374f283f0e2581b5cb9077e"
   },
   "source": [
    "Key insights : \n",
    "            - No missing values in the dataset\n",
    "            - All numerical features but 'sex'\n",
    "            - Though features are not normaly distributed, are close to normality\n",
    "            - None of the features have minimum = 0 except Height (requires re-check)\n",
    "            - Each feature has difference scale range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbad8ace48d984df41c92ec10b789d9e51a957ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.hist(figsize=(20,10), grid=False, layout=(2, 4), bins = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6abec3784ae308f4a6389f10a2e3ee012182cf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_features = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = data.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3b436f508202f02fe0005ac8f858da5a769c15c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb034d4b75c8d8e023f8bee544422f3b5e03246d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dae3a06f78828b6742289219e8152e8d8072dad4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "skew_values = skew(data[numerical_features], nan_policy = 'omit')\n",
    "dummy = pd.concat([pd.DataFrame(list(numerical_features), columns=['Features']), \n",
    "           pd.DataFrame(list(skew_values), columns=['Skewness degree'])], axis = 1)\n",
    "dummy.sort_values(by = 'Skewness degree' , ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a3c1617c524c624841f02defa4c5541ec3ee5b5"
   },
   "source": [
    "For normally distributed data, the skewness should be about 0. For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution. The function skewtest can be used to determine if the skewness value is close enough to 0, statistically speaking.\n",
    "        - Height has highest skewedness followed by age, Shucked weight (can be cross verified through histogram plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01c3f04cba9ee61dced6bce0fc56a8b5c729bd83",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing_values = data.isnull().sum().sort_values(ascending = False)\n",
    "percentage_missing_values = (missing_values/len(data))*100\n",
    "pd.concat([missing_values, percentage_missing_values], axis = 1, keys= ['Missing values', '% Missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7c28a8e7ed7e00c64200e5b02ad963a601b3c42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Sex', data = data, palette=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e70607040f0bd467b19d4cf7f385af94f2f2279",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.groupby('Sex')[['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
    "       'Viscera weight', 'Shell weight', 'age']].mean().sort_values('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c700e66b729aad1e88749c41bbde87fa2f4fa9b6"
   },
   "source": [
    "## Bivariate Analysis\n",
    "Bivariate analysis is vital part of data analysis process for, it gives clear picture on how each features are affected in presence of other features.  \n",
    "It also helps us understand and identify significance features, overcome multi-collinearity effect, inter-dependency and thus, provides insights on hidden data noise pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4e4159c1ca6d07636089b433f1583a506b72d77"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data[numerical_features]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c96d7ded4500d2701d9db10e3f0cadae4b1f797"
   },
   "source": [
    "key insights\n",
    "            length is linearly correlated with diameter while, non-linear relation with height, whole weight, shucked weight, viscera weight and shell weight\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c48f9a8832bef25271deed243c0f850bb0985483",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.heatmap(data[numerical_features].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f35c6e25824de2fa6447d023dc5a349319d22746"
   },
   "source": [
    "## Outliers handlings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf41a980fb08dfe6f15e07f1bab5b73a35ac3e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "dummy_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32658fecce28bc0a71e78687fea1589280e2d638",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.boxplot( rot = 90, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e966754fdf26e2c168c6a0d3d4809bb923ef3302",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'Viscera weight'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "820b5e081b8eba31dda76255118d2f480be2980c"
   },
   "outputs": [],
   "source": [
    "# outliers removal\n",
    "data.drop(data[(data['Viscera weight']> 0.5) & (data['age'] < 20)].index, inplace=True)\n",
    "data.drop(data[(data['Viscera weight']<0.5) & (data['age'] > 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d202787ddba0ea04703b32cfb3c11d0b8fb125cb"
   },
   "outputs": [],
   "source": [
    "var = 'Shell weight'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b5c121e6ed26feaa13a02eb7e342390d5ce716f"
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Shell weight']> 0.6) & (data['age'] < 25)].index, inplace=True)\n",
    "data.drop(data[(data['Shell weight']<0.8) & (data['age'] > 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e163356124f8899d23a6095311b062b51994f73"
   },
   "outputs": [],
   "source": [
    "var = 'Shucked weight'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05d95138b39174a1c7b225c70576111c3eb4235a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Shucked weight']>= 1) & (data['age'] < 20)].index, inplace=True)\n",
    "data.drop(data[(data['Shucked weight']<1) & (data['age'] > 20)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d8037f5406af07090b148d6de0507d393d6995b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'Whole weight'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71ba33c6841ab15e5397c4d6b7b8f819be09c649",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Whole weight']>= 2.5) & (data['age'] < 25)].index, inplace=True)\n",
    "data.drop(data[(data['Whole weight']<2.5) & (data['age'] > 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c9571d7bf19a43b87953a682e072142a20af62e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'Diameter'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "626eaa47a20bd430f5d4e721198504ca0456504b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Diameter']<0.1) & (data['age'] < 5)].index, inplace=True)\n",
    "data.drop(data[(data['Diameter']<0.6) & (data['age'] > 25)].index, inplace=True)\n",
    "data.drop(data[(data['Diameter']>=0.6) & (data['age']< 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7ff8412dc3d2be1228e214800e7eb6df50823e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'Height'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34d3964676d1bf17a08d4f5e15f71741931368ef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Height']>0.4) & (data['age'] < 15)].index, inplace=True)\n",
    "data.drop(data[(data['Height']<0.4) & (data['age'] > 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52172558fbcc8dc1947823a4519b5394272d65e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'Length'\n",
    "plt.scatter(x = data[var], y = data['age'],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1545bc72f83d245023c0abd1a94a6b9bac5ec8cc",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(data[(data['Length']<0.1) & (data['age'] < 5)].index, inplace=True)\n",
    "data.drop(data[(data['Length']<0.8) & (data['age'] > 25)].index, inplace=True)\n",
    "data.drop(data[(data['Length']>=0.8) & (data['age']< 25)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e86b69d2eae03347aacbdc855825acadd43c792"
   },
   "source": [
    "## Preprocessing, Modeling, Evaluation\n",
    "The base steps followed in any data modeling pipelines are:\n",
    "               - pre-processing \n",
    "               - suitable model selection\n",
    "               - modeling\n",
    "               - hyperparamaters tunning using GridSearchCV\n",
    "               - evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8748d1c32064154468e3df477ebe64f2383f1ad3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop('age', axis = 1)\n",
    "y = data['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f76f0ad0c0f12b88496d79fbd6a173a4aa5e0fb0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "standardScale = StandardScaler()\n",
    "standardScale.fit_transform(X)\n",
    "\n",
    "selectkBest = SelectKBest()\n",
    "X_new = selectkBest.fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2719b5f2ca2a1398e7e4eac8cd939efda8ecfe4f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "def rmse_cv(model, X_train, y):\n",
    "    rmse =- (cross_val_score(model, X_train, y, scoring='neg_mean_squared_error', cv=5))\n",
    "    return(rmse*100)\n",
    "\n",
    "models = [LinearRegression(),\n",
    "             Ridge(),\n",
    "             SVR(),\n",
    "             RandomForestRegressor(),\n",
    "             GradientBoostingRegressor(),\n",
    "             KNeighborsRegressor(n_neighbors = 4),]\n",
    "\n",
    "names = ['LR','Ridge','svm','GNB','RF','GB','KNN']\n",
    "\n",
    "for model,name in zip(models,names):\n",
    "    score = rmse_cv(model,X_train,y_train)\n",
    "    print(\"{}    : {:.6f}, {:4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21d1e8553cb3c2c23013fd4111dc139dc9878111"
   },
   "source": [
    "You have seen the perofrmance of each one of above models.\n",
    "\n",
    "So, according to you which model should we start or choose?\n",
    "Well the answer lies in Occam's razor principle from philosophy https://simple.wikipedia.org/wiki/Occam%27s_razor.\" Suppose there exist two explanations for an occurrence. In this case the simpler one is usually better. Another way of saying it is that the more assumptions you have to make, the more unlikely an explanation.\"\n",
    "Hence, starting with the simplest model Ridge, for various reasons:\n",
    "            - Feature Dimension is less\n",
    "            - No misisng values\n",
    "            - Few categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "adf0d1897b464aca95e96109999da3022ad86fdd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['age'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    #dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = -cross_val_score(alg, dtrain[predictors], dtrain['age'], cv=cv_folds, \n",
    "                                                    scoring='r2')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print( \"RMSE : %.4g\" % mean_squared_error(dtrain['age'].values, dtrain_predictions))\n",
    "    print( \"R2 Score (Train): %f\" % r2_score(dtrain['age'], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print( \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),\n",
    "                                                                                 np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.coef_, predictors).sort_values(ascending=False)\n",
    "        plt.figure(figsize=(20,4))\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5458fb52e377940e95207bd731c76acfc677521f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base Model\n",
    "predictors = [x for x in data.columns if x not in ['age']]\n",
    "lrm0 = Ridge(random_state=10)\n",
    "modelfit(lrm0, data, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f763b30aebcc52e636d6d21f36795cf3b0e96084"
   },
   "source": [
    "## Hyperparameter tunning using GrideSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6014efdc79f204d14b1860e90155732bbfc1870e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's do hyperparameter tunning using GrideSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "param  = {'alpha':[0.01, 0.1, 1,10,100],\n",
    "         'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "glrm0 = GridSearchCV(estimator = Ridge(random_state=10,),\n",
    "param_grid = param,scoring= 'r2' ,cv = 5,  n_jobs = -1)\n",
    "glrm0.fit(X_train, y_train)\n",
    "glrm0.best_params_, glrm0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed5e3a93f4d4a4c6c22b155a4c3a39679ba5f497",
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelfit(Ridge(alpha = 0.1,random_state=10,), data, predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
